{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://www.kdd.org/exploration_files/KDDCUP2005Report_Shen.pdf\n",
    "# http://research.microsoft.com/pubs/81350/sigir09.pdf\n",
    "# http://research.microsoft.com/pubs/79487/Query%20Enrichment%20for%20Web-query%20Classification.Shen.HKUST.TOIS.2006.Paper.pdf\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk.tag import pos_tag\n",
    "from itertools import compress\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# create a function to combine data files #\n",
    "###########################################\n",
    "\n",
    "def frame_masher():\n",
    "    # find all of the query files\n",
    "    query_files = glob.glob('data/Labeled800Queries/*')\n",
    "    \n",
    "    # empty list to add data frames to\n",
    "    frame_list = []\n",
    "    \n",
    "    # iterate through the files to create one combined date frame\n",
    "    for frame in query_files:\n",
    "        h = ['query','lab1','lab2','lab3','lab4','lab5' ]\n",
    "        df = pd.read_csv(frame,header=None, delimiter='\\t')\n",
    "        df.columns = h\n",
    "        frame_list.append(df)\n",
    "    joined = pd.concat(frame_list).reset_index()\n",
    "    final = joined.drop('index',axis = 1)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the frame\n",
    "df = frame_masher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# create a function to count how many words are in each query #\n",
    "###############################################################\n",
    "\n",
    "def word_counter():\n",
    "    \n",
    "    # create an empty list to add each row's value \n",
    "    word_count = []\n",
    "    \n",
    "    # iterate through each query, split it up and count the words\n",
    "    for i in df['query']:\n",
    "        count = len(i.split())\n",
    "        word_count.append(count)\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# create a function that informs us of whether or not there are numbers in the query #\n",
    "######################################################################################\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# create a function to apply the hasNumbers to each query #\n",
    "###########################################################\n",
    "\n",
    "def has_num():\n",
    "    number = []\n",
    "    for i in df['query']:\n",
    "        num = hasNumbers(i)\n",
    "        number.append(num)\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# create a function to count the characters per query #\n",
    "#######################################################\n",
    "\n",
    "def char_counter():\n",
    "    char_count = []\n",
    "    for string in df['query']:\n",
    "        count = len(string)\n",
    "        char_count.append(count)\n",
    "    return char_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# count the parts of speech per query #\n",
    "#######################################\n",
    "\n",
    "def partOfSpeechCounter(p='NN'): # others include 'VB' and 'IN'\n",
    "    part_count = []\n",
    "    for q in df['query']:\n",
    "        tagged = pos_tag(q.split())\n",
    "        part = [word for word,pos in tagged if pos == p]\n",
    "        part_count.append(len(part))\n",
    "    return part_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# create a function to combine categories into one column #\n",
    "###########################################################\n",
    "\n",
    "def categoryCombine():\n",
    "    \n",
    "    # join the category columns from the df into one string\n",
    "    cats = df[df.columns[1:6]].apply(lambda x: ','.join(x.dropna().astype(str).astype(str)),axis=1)\n",
    "    \n",
    "    # empty list \n",
    "    categories = []\n",
    "    \n",
    "    # transform string into list by splitting on commas\n",
    "    for val in cats:\n",
    "        splitted = val.split(',')\n",
    "        categories.append(splitted)\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find all super-categories\n",
    "super_categories = ['Computers','Entertainment','Information','Living','Online','Shopping','Sports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# create a function that returns true if the super-category #\n",
    "# exists in the categories column and faluse otherwise      #\n",
    "#############################################################\n",
    "\n",
    "def superCatBool():\n",
    "    sup_bool = []\n",
    "    for i in df['categories']:\n",
    "        sups = []\n",
    "        for category in super_categories:\n",
    "            sup = category in i\n",
    "            sups.append(sup)\n",
    "        sup_bool.append(sups)\n",
    "    return sup_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# a function to print out the super-categories associated with each row #\n",
    "#########################################################################\n",
    "\n",
    "def superCats():\n",
    "    cats = []\n",
    "    bools = superCatBool()\n",
    "    for vec in bools:\n",
    "        new = list(compress(super_categories, vec))\n",
    "        cats.append(new)\n",
    "    return cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert bools to string for R format\n",
    "def boolToString():\n",
    "    new_cells = []\n",
    "    for cell in df['sup_cat_bool']:\n",
    "        list_ = []\n",
    "        for i in cell:\n",
    "            if i == True:\n",
    "                x = 'TRUE'\n",
    "            else:\n",
    "                x = 'FALSE'\n",
    "            list_.append(x)\n",
    "        new_cells.append(list_)\n",
    "    return new_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['bools']=boolToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a way to create separate columns\n",
    "def boolRowMaker(x):\n",
    "    col = []\n",
    "    for i in df['bools']:\n",
    "        b = i[x]\n",
    "        col.append(b)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['word_count'] = word_counter()\n",
    "df['has_num'] = has_num()\n",
    "df['char_count']=char_counter()\n",
    "df['char_per_word'] =df['char_count']/df['word_count']\n",
    "df['categories'] = categoryCombine()\n",
    "df['super_categories'] = superCats()\n",
    "df['sup_cat_bool'] = superCatBool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c1e82772a73a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'noun_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartOfSpeechCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verb_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartOfSpeechCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prep_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartOfSpeechCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-2a24627afe89>\u001b[0m in \u001b[0;36mpartOfSpeechCounter\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpart_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtagged\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpart_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['noun_count'] = partOfSpeechCounter()\n",
    "df['verb_count'] = partOfSpeechCounter('VB')\n",
    "df['prep_count'] = partOfSpeechCounter('IN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create new columns\n",
    "df['label1']= boolRowMaker(0)\n",
    "df['label2']= boolRowMaker(1)\n",
    "df['label3']= boolRowMaker(2)\n",
    "df['label4']= boolRowMaker(3)\n",
    "df['label5']= boolRowMaker(4)\n",
    "df['label6']= boolRowMaker(5)\n",
    "df['label7']= boolRowMaker(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# split a string column into multiple column function #\n",
    "#######################################################\n",
    "\n",
    "foo = lambda x: pd.Series([i for i in reversed(x.split(','))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply foo to super_categories column\n",
    "rev=df['super_categories'].apply(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df['sup1'],df['sup2'],df['sup3'],df['sup4'] = rev[0],rev[1],rev[2],rev[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# clean up some ugliness with some regex matches #\n",
    "##################################################\n",
    "\n",
    "def colCleaner(column):\n",
    "    cleaned = []\n",
    "    for cell in column:    \n",
    "        x=cell.replace(r\"[\",\"\")\n",
    "        y = x.replace(r\"'\",\"\")\n",
    "        w = y.replace(r\" \",\"\")\n",
    "        z = w.replace(r\"]\",\"\")\n",
    "        cleaned.append(z)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace a column\n",
    "df['sup1']=colCleaner(df['sup1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/queries.csv') # write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
